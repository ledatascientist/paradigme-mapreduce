{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutoriel sur pyspark et MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration de l'environnement Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S'assurer d'avoir correctement installé pyspark et Spark\n",
    "# Importer quelques classes Spark pour initialiser notre environnement\n",
    "from pyspark import SparkContext, SparkConf\n",
    " \n",
    "# Initialiser Spark\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Création d'un RDD de données numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'> \t [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Créer un jeu de données\n",
    "data = list(range(10)) ## [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
    "# Créer un RDD\n",
    "rdd = sc.parallelize(data)\n",
    " \n",
    "print(type(rdd), '\\t', rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Création d'un RDD de chaînes de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'> \t [[], ['Ledatascientist'], ['le'], ['top'], ['des'], ['blogs'], ['français'], ['en'], ['Data'], ['Science']]\n"
     ]
    }
   ],
   "source": [
    "# Créer un jeu de données\n",
    "data = ['Ledatascientist', 'le', 'top', 'des', 'blogs', 'français', 'en', 'Data', 'Science']\n",
    "# Créer un RDD\n",
    "rdd = sc.parallelize(data, numSlices=10).glom()\n",
    " \n",
    "print(type(rdd), '\\t', rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application\n",
    "Nous voulons **calculer le nombre d’occurrences des mots dans un texte quelconque**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Lecture de notre fichier TXT\n",
    "Nous créerons un RDD à partir d’un fichier ```example.txt``` qui contient notre article sur [les bases du Machine Learning](https://ledatascientist.com/machine-learning-les-bases/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'> \n",
      " Machine Learning ou apprentissage automatique est l’un des champs de l’intelligence artificielle (IA). Ce domaine apparu tout au début des années 1960 va devenir de nos jours très incontournable au XXIe siècle pour la résolution de problèmes concrets et complexes.\n"
     ]
    }
   ],
   "source": [
    "# Créer un RDD à partir d'un fichier TXT\n",
    "rdd = sc.textFile(\"./example.txt\")\n",
    "# Affichage du premier élément de notre RDD\n",
    "print(type(rdd), '\\n', rdd.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Définition de notre fonction de *mapping*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sentence):\n",
    "    \"\"\"\n",
    "    Supprime les ponctuations d'une phrase, la splitte en liste \n",
    "    et retourne la liste des mots (en miniscule) dont la longueur est supérieure à 3.\n",
    "     \n",
    "    Parameter\n",
    "    ----------\n",
    "    sentence: str\n",
    "        Une phrase.\n",
    "     \n",
    "    Returns\n",
    "    --------\n",
    "    words: list\n",
    "        La liste des mots de la phrase \"sentence\" dont la longueur est supérieure à 3.\n",
    "    \"\"\"\n",
    "     \n",
    "    ## Suppression des ponctuations\n",
    "    for p in \"`!()-_[]{};:’,./?\\\"\":\n",
    "        sentence = sentence.replace(p, \" \")\n",
    "     \n",
    "    ## Split de la phrase\n",
    "    list_ = sentence.split()\n",
    "     \n",
    "    ## Liste des mots de longueur supérieure à 3\n",
    "    words = [word.lower() for word in list_ if len(word) > 3]\n",
    "     \n",
    "    ## Sortie de notre fonction\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Création de notre RDD transformé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine',\n",
       " 'learning',\n",
       " 'apprentissage',\n",
       " 'automatique',\n",
       " 'champs',\n",
       " 'intelligence',\n",
       " 'artificielle',\n",
       " 'domaine',\n",
       " 'apparu',\n",
       " 'tout',\n",
       " 'début',\n",
       " 'années',\n",
       " '1960',\n",
       " 'devenir',\n",
       " 'jours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer le nouveau RDD\n",
    "rdd_processed = rdd.flatMap(process)\n",
    "# Affichage des quinze premiers éléments de notre RDD\n",
    "rdd_processed.take(15) ## take(1) == first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Application du MapReduce\n",
    "Nous affichons la liste des **cinq mots les plus récurrents du texte**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machine', 17),\n",
       " ('apprentissage', 13),\n",
       " ('learning', 12),\n",
       " ('supervisé', 10),\n",
       " ('régression', 9)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map - Reduce - Sort\n",
    "rdd_final = rdd_processed.map(lambda word: (word, 1))\\\n",
    "                            .reduceByKey(lambda a, b: a+b)\\\n",
    "                                .sortBy(lambda x: -x[1])\n",
    " \n",
    "# Afficher les cinq premiers éléments\n",
    "rdd_final.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
